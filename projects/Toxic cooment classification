# using NLP and Logistic regression
import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from textblob import TextBlob
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE

# Load the dataset
data = pd.read_csv('train.csv')

# Download NLTK resources
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt')

# Initialize stopwords and lemmatizer
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

# Function to preprocess text
def preprocess_text(text):
    # Lowercasing
    text = text.lower()
    # Removing punctuation and special characters
    text = re.sub(r'[^a-z\s]', '', text)
    # Removing stop words
    words = text.split()
    words = [word for word in words if word not in stop_words]
    # Lemmatization
    words = [lemmatizer.lemmatize(word) for word in words]
    return ' '.join(words)

# Apply preprocessing to the 'comment_text' column
data['cleaned_text'] = data['comment_text'].apply(preprocess_text)

# Add sentiment polarity as a feature
data['sentiment'] = data['comment_text'].apply(lambda x: TextBlob(x).sentiment.polarity)

# Function to identify specific n-grams (e.g., offensive phrases)
def contains_offensive_ngram(text):
    offensive_phrases = ['go away', 'you idiot', 'shut up', 'hate you', 'stupid']
    return any(phrase in text for phrase in offensive_phrases)

data['has_offensive_ngram'] = data['cleaned_text'].apply(contains_offensive_ngram)

# Convert `has_offensive_ngram` to integer (0 or 1)
data['has_offensive_ngram'] = data['has_offensive_ngram'].astype(int)

# Initialize TfidfVectorizer and transform the 'cleaned_text' column
tfidf_vectorizer = TfidfVectorizer()
X_tfidf = tfidf_vectorizer.fit_transform(data['cleaned_text'])

# Combine TF-IDF features with sentiment and n-gram features
import scipy.sparse as sp

X = sp.hstack((X_tfidf, 
               sp.csr_matrix(data[['sentiment', 'has_offensive_ngram']].values)))

# Target variable
y = data['toxic']

# Handle class imbalance using SMOTE
smote = SMOTE()
X_resampled, y_resampled = smote.fit_resample(X, y)

# Split the dataset into training and validation sets
X_train, X_valid, y_train, y_valid = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

# Initialize and train Logistic Regression model
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = model.predict(X_valid)

# Evaluate the model
print("Classification Report:")
print(classification_report(y_valid, y_pred))

print("\nConfusion Matrix:")
print(confusion_matrix(y_valid, y_pred))

# Function to preprocess and classify new comments
def classify_comments(comments):
    # Preprocess the new comments
    processed_comments = [preprocess_text(comment) for comment in comments]
    
    # Transform the comments using the trained TF-IDF vectorizer
    X_new_tfidf = tfidf_vectorizer.transform(processed_comments)
    
    # Create additional features (sentiment and offensive n-grams)
    new_sentiment = [TextBlob(comment).sentiment.polarity for comment in comments]
    new_ngram = [contains_offensive_ngram(preprocess_text(comment)) for comment in comments]
    
    # Combine features
    X_new = sp.hstack((X_new_tfidf, 
                       sp.csr_matrix(pd.DataFrame({'sentiment': new_sentiment, 'has_offensive_ngram': new_ngram}).values)))
    
    # Predict toxicity using the trained model
    predictions = model.predict(X_new)
    
    # Return the predictions
    return predictions

# Example new comments
new_comments = [
    "I love this product!",
    "This is the worst experience ever.",
    "Iâ€™m so happy with my purchase.",
    "I hate everything about this service.",
    "Go away, you idiot!"
]

# Classify the new comments
predictions = classify_comments(new_comments)

# Display the results
for comment, prediction in zip(new_comments, predictions):
    print(f"Comment: '{comment}'\nPrediction: {'Toxic' if prediction == 1 else 'Non-Toxic'}\n")
